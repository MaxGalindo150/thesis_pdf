El deep learning ha revolucionado la reconstrucción de imágenes fotoacústicas a partir de datos crudos (raw data) provenientes de sensores, donde un eje representa el tiempo y el otro la dirección de escaneo. Las aproximaciones han evolucionado desde el uso de métodos convencionales complementados con deep learning para mejorar la calidad de imagen, hasta el desarrollo de redes neuronales que aprenden a reconstruir la imagen directamente desde los datos crudos. En este contexto, la arquitectura U-Net se ha convertido en un estándar de facto.
Sin embargo, el principal desafío al usar redes neuronales para la reconstrucción directa radica en la física subyacente del problema, que lo hace matemáticamente mal condicionado. Aunque existen métodos como las Physics Informed Neural Networks (PINN) para incorporar restricciones físicas, estos suelen ser computacionalmente costosos debido a las numerosas operaciones numéricas requeridas. En este trabajo, proponemos un nuevo marco de trabajo que permite a la red neuronal no solo reconstruir la imagen sino también mantener la consistencia física del problema.

Nuestra propuesta se basa en un enfoque inspirado en el data guided learning, que consta de dos fases principales. En la primera, entrenamos dos redes U-Net: una aprende a reconstruir imágenes a partir de datos crudos, mientras que la otra aprende el problema inverso, es decir, la generación de señales fotoacústicas a partir de imágenes, simulando así el proceso físico de propagación de ondas acústicas. En la segunda fase, realizamos un fine-tuning de la red de reconstrucción, incorporando la consistencia física como una restricción adicional en el proceso de aprendizaje. Este enfoque actúa como un supervisor que guía a la red para que no solo aprenda a reconstruir imágenes con alta calidad, sino que también respete los principios físicos fundamentales del proceso fotoacústico.